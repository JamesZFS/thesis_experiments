{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of a Tree Clustering Algorithm\n",
    "\n",
    "Given samples $\\{\\mathbf x_i, y_i \\}$, we classify the samples in an *unsupervised* manner using a decision-tree-like algorithm, meaning that the ground truth labels $y_i$ are invisible to the algorithm. We then evaluate the trees by computing the loss-depth curve, which shows at given depth of the tree, how well is the clustering performance.\n",
    "\n",
    "For example, we can use the impurity as the loss function. Suppose at depth $d$, the tree consists of $m_d$ nodes, each of which contains reigon $\\{ R^d_i \\}_{i=1}^{m_d}$. Suppose there are $c$ ground truth classes (number of geometries in the scene). The loss the tree at depth $d$ is defined as\n",
    "\n",
    "$$\n",
    "\n",
    "L(d) = \\sum_{i=1}^{m_d} \\mathbb P(\\mathbf x \\in R^d_i) \\cdot \\mathrm{Imp}(R^d_i) \\\\\n",
    "\n",
    "\\mathrm{Imp}(R) = \\sum_{j=1}^c - \\mathbb P(y = j | \\mathbf x \\in R) \\log \\mathbb P(y = j | \\mathbf x \\in R)\n",
    "\n",
    "$$\n",
    "\n",
    "Suppose the count of each class in region $R$ is $\\{ n_j \\}_{j=1}^c$, then\n",
    "\n",
    "$$\n",
    "\n",
    "\\mathrm{Imp}(R) = \\sum_{j=1}^c - \\frac{n_j}{\\sum_{k=1}^c n_k} \\log \\frac{n_j}{\\sum_{k=1}^c n_k}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
